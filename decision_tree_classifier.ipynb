{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "data: (N, n_features +1) (last columns are the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "data = np.hstack((X,y.reshape(-1, 1)))\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [4.9, 3.6, 1.4, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[:,0] <5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Question:\n",
    "    def __init__(self, feature, threshold):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def answer(self, x):\n",
    "        if x[self.feature] < self.threshold: return True\n",
    "        return False\n",
    "    \n",
    "    def partition(self, rows):\n",
    "        left_data, right_data = [], []\n",
    "        for row in rows:\n",
    "            if self.answer(row):\n",
    "                left_data.append(row)\n",
    "            else:\n",
    "                right_data.append(row)\n",
    "        return left_data, right_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, question):\n",
    "        self.question = question\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "def compute_frequencies(labels):\n",
    "    freq = Counter(labels)\n",
    "    for label, occurrence in freq.items():\n",
    "        freq[label] = occurrence / len(labels)\n",
    "    return freq\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, labels):\n",
    "        self.probabilities = compute_frequencies(labels)\n",
    "\n",
    "\n",
    "def gini_loss(data):\n",
    "    frequencies = compute_frequencies(data[:,-1])\n",
    "    gini = 0\n",
    "    for frequency in frequencies.values():\n",
    "        gini += frequency * (1 - frequency)\n",
    "    return gini\n",
    "\n",
    "\n",
    "def entropy_loss(data):\n",
    "    frequencies = compute_frequencies(data[:,-1])\n",
    "    entropy = 0\n",
    "    for frequency in frequencies.values():\n",
    "        entropy -= frequency * np.log(frequency)\n",
    "    return entropy\n",
    "\n",
    "#%%\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, loss=gini_loss):\n",
    "        self.root = None\n",
    "        self.loss = loss\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.root = self.build_tree(data)\n",
    "\n",
    "    def build_tree(self,data):\n",
    "        gain, question = self.find_best_split(data)\n",
    "        if gain == 0:\n",
    "            return LeafNode(labels=data[:,-1])\n",
    "        node = DecisionNode(question)\n",
    "        left_data, right_data = question.partition(data) \n",
    "        node.left = self.build_tree(left_data)\n",
    "        node.right = self.build_tree(right_data)\n",
    "        return node\n",
    "\n",
    "    def find_best_split(self, data):\n",
    "        current_loss = self.loss(data)\n",
    "        best_gain = 0\n",
    "        best_question = None\n",
    "        for feature in range(data.shape[1] - 1):\n",
    "            unique_values = set(data[:, feature])\n",
    "            for threshold in unique_values:\n",
    "                question = Question(feature=feature, threshold=threshold)\n",
    "                left_data, right_data = question.partition(data)\n",
    "                split_gain = self.compute_split_gain(left_data, right_data, current_loss)\n",
    "                if split_gain > best_gain:\n",
    "                    best_gain, best_question = split_gain, question\n",
    "                    \n",
    "\n",
    "        return best_gain, best_question\n",
    "\n",
    "    def compute_split_gain(self, left_data, right_data, current_loss):\n",
    "        p = len(left_data) / (len(left_data) + len(right_data))\n",
    "        left_loss = self.loss(left_data)\n",
    "        right_loss = self.loss(right_data)\n",
    "        return current_loss - (p * left_loss + (1-p) * right_loss)\n",
    "\n",
    "    def predict_class(self, x):\n",
    "        return self.predict_proba(x).most_common(1)[0]\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"traverse tree + get counts of classes in the leaf\"\"\"\n",
    "        node = self.root\n",
    "        while not isinstance(node, LeafNode):\n",
    "            node = node.decide(x)\n",
    "        return node.probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m d\u001b[39m.\u001b[39;49mfit(data)\n",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_tree(data)\n",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36mDecisionTreeClassifier.build_tree\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_tree\u001b[39m(\u001b[39mself\u001b[39m,data):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     gain, question \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_best_split(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mif\u001b[39;00m gain \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m LeafNode(labels\u001b[39m=\u001b[39mdata[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36mDecisionTreeClassifier.find_best_split\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m question \u001b[39m=\u001b[39m Question(feature\u001b[39m=\u001b[39mfeature, threshold\u001b[39m=\u001b[39mthreshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m left_data, right_data \u001b[39m=\u001b[39m question\u001b[39m.\u001b[39mpartition(data)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m split_gain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_split_gain(left_data, right_data, current_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m split_gain \u001b[39m>\u001b[39m best_gain:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     best_gain, best_question \u001b[39m=\u001b[39m split_gain, question\n",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36mDecisionTreeClassifier.compute_split_gain\u001b[0;34m(self, left_data, right_data, current_loss)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_split_gain\u001b[39m(\u001b[39mself\u001b[39m, left_data, right_data, current_loss):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(left_data) \u001b[39m/\u001b[39m (\u001b[39mlen\u001b[39m(left_data) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(right_data))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     left_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(left_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     right_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(right_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m current_loss \u001b[39m-\u001b[39m (p \u001b[39m*\u001b[39m left_loss \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mp) \u001b[39m*\u001b[39m right_loss)\n",
      "\u001b[1;32m/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb Cell 8\u001b[0m in \u001b[0;36mgini_loss\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgini_loss\u001b[39m(data):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     frequencies \u001b[39m=\u001b[39m compute_frequencies(data[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     gini \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/taylor/Documents/ML_data_coding/machine_learning_algorithms/decision_tree_classifier.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m frequency \u001b[39min\u001b[39;00m frequencies\u001b[39m.\u001b[39mvalues():\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "d.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df2288654b2a21ce744624914d1926872c87a5f09f35bbaf4bb42f7145e25b6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
